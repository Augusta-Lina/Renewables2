{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# 7 \u2014 Stacking Ensemble: All Targets\nPer-horizon stacking with 5-fold temporal CV. 4 tabular base models (XGBoost, LightGBM, Ridge, Random Forest) + TSO \u2192 Ridge meta-learner.\n\nFor solar & price, PatchTST predictions are included as an additional meta-feature.\n\n**Requires**: Run notebook 06 first to generate PatchTST prediction CSVs (for solar & price targets).",
   "id": "cell-0"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import xgboost as xgb\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "except ImportError:\n",
    "    import subprocess, sys\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', 'lightgbm'])\n",
    "    import lightgbm as lgb\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "df = pd.read_parquet('../cleaned_data.parquet')\n",
    "df['time'] = pd.to_datetime(df['time'], utc=True)\n",
    "\n",
    "train_mask = df['time'].dt.year <= 2017\n",
    "train_end = int(train_mask.sum())\n",
    "test_start = train_end\n",
    "context_length = 168\n",
    "prediction_length = 24\n",
    "\n",
    "print(f'Shape: {df.shape}')\n",
    "print(f'Train: {train_end}, Test: {len(df) - train_end}')"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Shape: (35056, 80)\n",
      "Train: 26280, Test: 8776\n"
     ]
    }
   ],
   "id": "cell-1"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def extract_tabular_features(df, target_col, weather_cols, window_start, h):\n",
    "    \"\"\"Extract features for one (window, horizon) pair.\"\"\"\n",
    "    target_idx = window_start + h\n",
    "\n",
    "    # Weather at target hour\n",
    "    weather = df[weather_cols].iloc[target_idx].values.astype(float)\n",
    "\n",
    "    # Time features\n",
    "    t = df['time'].iloc[target_idx]\n",
    "    time_feats = np.array([t.hour, t.month, t.dayofweek, int(t.dayofweek >= 5)], dtype=float)\n",
    "\n",
    "    # Context statistics on target series\n",
    "    start_168 = max(0, target_idx - 168)\n",
    "    start_24 = max(0, target_idx - 24)\n",
    "    ctx_168 = df[target_col].iloc[start_168 : target_idx].values.astype(float)\n",
    "    ctx_24 = df[target_col].iloc[start_24 : target_idx].values.astype(float)\n",
    "\n",
    "    if len(ctx_24) == 0:\n",
    "        ctx_24 = np.array([0.0])\n",
    "    if len(ctx_168) == 0:\n",
    "        ctx_168 = np.array([0.0])\n",
    "\n",
    "    stats = np.array([\n",
    "        np.mean(ctx_24), np.std(ctx_24), np.min(ctx_24), np.max(ctx_24),\n",
    "        np.mean(ctx_168), np.std(ctx_168), np.min(ctx_168), np.max(ctx_168),\n",
    "        ctx_168[-1],\n",
    "    ])\n",
    "\n",
    "    return np.concatenate([weather, time_feats, stats])\n",
    "\n",
    "print('Feature extraction function defined')"
   ],
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Feature extraction function defined\n"
     ]
    }
   ],
   "id": "cell-2"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Load PatchTST predictions\n",
    "pt_solar_train = pd.read_csv('patchtst_solar_train_predictions.csv')\n",
    "pt_solar_test = pd.read_csv('patchtst_solar_predictions.csv')\n",
    "pt_price_train = pd.read_csv('patchtst_price_train_predictions.csv')\n",
    "pt_price_test = pd.read_csv('patchtst_price_predictions.csv')\n",
    "\n",
    "print(f'PatchTST solar \u2014 train: {len(pt_solar_train)}, test: {len(pt_solar_test)}')\n",
    "print(f'PatchTST price \u2014 train: {len(pt_price_train)}, test: {len(pt_price_test)}')\n",
    "\n",
    "# Compute window starts (same as PatchTST notebook)\n",
    "train_window_starts = list(range(context_length, train_end - prediction_length, prediction_length))\n",
    "test_window_starts = []\n",
    "for i in range(test_start, len(df) - prediction_length, prediction_length):\n",
    "    if i - context_length >= 0:\n",
    "        test_window_starts.append(i)\n",
    "\n",
    "print(f'Train windows: {len(train_window_starts)}, Test windows: {len(test_window_starts)}')"
   ],
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "PatchTST solar \u2014 train: 26112, test: 8736\n",
      "PatchTST price \u2014 train: 26112, test: 8736\n",
      "Train windows: 1088, Test windows: 364\n"
     ]
    }
   ],
   "id": "cell-3"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "def get_base_models():\n    return {\n        'xgb': xgb.XGBRegressor(n_estimators=200, max_depth=4, learning_rate=0.1,\n                                random_state=42, verbosity=0, tree_method='hist'),\n        'lgbm': lgb.LGBMRegressor(n_estimators=200, max_depth=4, learning_rate=0.1,\n                                  random_state=42, verbose=-1),\n        'ridge': Ridge(alpha=1.0),\n        'rf': RandomForestRegressor(n_estimators=100, max_depth=8, random_state=42, n_jobs=-1),\n    }\n\n\ndef run_stacking(df, target_col, tso_col, weather_cols,\n                 train_ws, test_ws, pt_train_df=None, pt_test_df=None,\n                 prediction_length=24, n_folds=5, clip_min=None):\n    \"\"\"Per-horizon stacking with K-fold CV. PatchTST predictions are optional.\"\"\"\n    n_train = len(train_ws)\n    n_test = len(test_ws)\n    all_preds = np.zeros((n_test, prediction_length))\n    all_actuals = np.zeros((n_test, prediction_length))\n    all_tso = np.zeros((n_test, prediction_length))\n\n    use_patchtst = pt_train_df is not None and pt_test_df is not None\n    if use_patchtst:\n        pt_train_idx = pt_train_df.set_index(['window', 'horizon'])['patchtst_pred']\n        pt_test_idx = pt_test_df.set_index(['window', 'horizon'])['patchtst_pred']\n\n    model_names = list(get_base_models().keys())\n\n    for h in range(prediction_length):\n        X_train = np.array([extract_tabular_features(df, target_col, weather_cols, ws, h)\n                           for ws in train_ws])\n        y_train = np.array([df[target_col].iloc[ws + h] for ws in train_ws])\n        tso_train = np.array([df[tso_col].iloc[ws + h] for ws in train_ws])\n\n        X_test = np.array([extract_tabular_features(df, target_col, weather_cols, ws, h)\n                          for ws in test_ws])\n        y_test = np.array([df[target_col].iloc[ws + h] for ws in test_ws])\n        tso_test = np.array([df[tso_col].iloc[ws + h] for ws in test_ws])\n\n        if use_patchtst:\n            pt_train = np.array([pt_train_idx.loc[(w, h)] for w in range(n_train)])\n            pt_test = np.array([pt_test_idx.loc[(w, h)] for w in range(n_test)])\n\n        # 5-fold temporal CV for OOF predictions\n        fold_size = n_train // n_folds\n        oof_preds = {name: np.zeros(n_train) for name in model_names}\n\n        for fold in range(n_folds):\n            val_start = fold * fold_size\n            val_end = (fold + 1) * fold_size if fold < n_folds - 1 else n_train\n            train_idx = list(range(val_start)) + list(range(val_end, n_train))\n            val_idx = list(range(val_start, val_end))\n\n            for name in model_names:\n                m = get_base_models()[name]\n                m.fit(X_train[train_idx], y_train[train_idx])\n                oof_preds[name][val_idx] = m.predict(X_train[val_idx])\n\n        # Stack: OOF + TSO [+ PatchTST] -> Ridge meta-learner\n        meta_cols = [oof_preds[n] for n in model_names] + [tso_train]\n        if use_patchtst:\n            meta_cols.append(pt_train)\n        meta_train = np.column_stack(meta_cols)\n        meta = Ridge(alpha=1.0)\n        meta.fit(meta_train, y_train)\n\n        # Retrain base models on full train -> predict test\n        test_base_preds = {}\n        for name in model_names:\n            m = get_base_models()[name]\n            m.fit(X_train, y_train)\n            test_base_preds[name] = m.predict(X_test)\n\n        test_meta_cols = [test_base_preds[n] for n in model_names] + [tso_test]\n        if use_patchtst:\n            test_meta_cols.append(pt_test)\n        meta_test = np.column_stack(test_meta_cols)\n        final_pred = meta.predict(meta_test)\n\n        if clip_min is not None:\n            final_pred = np.clip(final_pred, clip_min, None)\n\n        all_preds[:, h] = final_pred\n        all_actuals[:, h] = y_test\n        all_tso[:, h] = tso_test\n\n        if (h + 1) % 6 == 0:\n            print(f'  Horizon {h+1}/{prediction_length} done')\n\n    return all_preds, all_actuals, all_tso\n\nprint('Stacking function defined (PatchTST optional)')",
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Stacking function defined (PatchTST optional)\n"
     ]
    }
   ],
   "id": "cell-4"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Solar stacking\n",
    "solar_weather_cols = [\n",
    "    'clouds_all_madrid', 'clouds_all_bilbao', 'clouds_all_barcelona',\n",
    "    'clouds_all_seville', 'clouds_all_valencia',\n",
    "    'temp_madrid', 'temp_bilbao', 'temp_barcelona',\n",
    "    'temp_seville', 'temp_valencia',\n",
    "    'temp_max_madrid', 'temp_max_bilbao', 'temp_max_barcelona',\n",
    "    'temp_max_seville', 'temp_max_valencia',\n",
    "    'humidity_madrid', 'humidity_bilbao', 'humidity_barcelona',\n",
    "    'humidity_seville', 'humidity_valencia',\n",
    "]\n",
    "\n",
    "print('=== Stacking Ensemble for Solar ===')\n",
    "solar_preds, solar_actuals, solar_tso = run_stacking(\n",
    "    df, 'generation solar', 'forecast solar day ahead', solar_weather_cols,\n",
    "    train_window_starts, test_window_starts,\n",
    "    pt_solar_train, pt_solar_test,\n",
    "    clip_min=0,\n",
    ")\n",
    "print('Solar stacking complete')"
   ],
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "=== Stacking Ensemble for Solar ===\n",
      "  Horizon 6/24 done\n",
      "  Horizon 12/24 done\n",
      "  Horizon 18/24 done\n",
      "  Horizon 24/24 done\n",
      "Solar stacking complete\n"
     ]
    }
   ],
   "id": "cell-5"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Solar metrics\n",
    "flat_pred_s = solar_preds.flatten()\n",
    "flat_act_s = solar_actuals.flatten()\n",
    "flat_tso_s = solar_tso.flatten()\n",
    "\n",
    "stack_mae_s = np.mean(np.abs(flat_act_s - flat_pred_s))\n",
    "stack_rmse_s = np.sqrt(np.mean((flat_act_s - flat_pred_s) ** 2))\n",
    "stack_mape_s = np.mean(np.abs((flat_act_s - flat_pred_s) / np.clip(np.abs(flat_act_s), 1, None))) * 100\n",
    "\n",
    "tso_mae_s = np.mean(np.abs(flat_act_s - flat_tso_s))\n",
    "tso_rmse_s = np.sqrt(np.mean((flat_act_s - flat_tso_s) ** 2))\n",
    "\n",
    "print(f'{\"Metric\":<14} {\"Stacking\":>12} {\"TSO\":>12} {\"Improvement\":>12}')\n",
    "print('-' * 52)\n",
    "print(f'{\"MAE (MW)\":<14} {stack_mae_s:>12.1f} {tso_mae_s:>12.1f} {(1 - stack_mae_s / tso_mae_s) * 100:>+11.1f}%')\n",
    "print(f'{\"RMSE (MW)\":<14} {stack_rmse_s:>12.1f} {tso_rmse_s:>12.1f} {(1 - stack_rmse_s / tso_rmse_s) * 100:>+11.1f}%')\n",
    "print(f'{\"MAPE (%)\":<14} {stack_mape_s:>12.1f}')"
   ],
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Metric            Stacking          TSO  Improvement\n",
      "----------------------------------------------------\n",
      "MAE (MW)           203.7        141.1       -44.4%\n",
      "RMSE (MW)          302.0        226.3       -33.5%\n",
      "MAPE (%)           203.7\n"
     ]
    }
   ],
   "id": "cell-6"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Export stacking_solar.json\n",
    "os.makedirs('../dashboard/public/data', exist_ok=True)\n",
    "\n",
    "sample_data_s = []\n",
    "for w in range(9, 16):\n",
    "    if w >= len(test_window_starts):\n",
    "        break\n",
    "    ws = test_window_starts[w]\n",
    "    for h in range(prediction_length):\n",
    "        t = df['time'].iloc[ws + h]\n",
    "        sample_data_s.append({\n",
    "            'time': t.strftime('%Y-%m-%d %H:%M'),\n",
    "            'actual': round(float(solar_actuals[w, h]), 1),\n",
    "            'predicted': round(float(solar_preds[w, h]), 1),\n",
    "            'tso': round(float(solar_tso[w, h]), 1),\n",
    "        })\n",
    "\n",
    "output_s = {\n",
    "    'target': 'solar',\n",
    "    'model': 'Stacking Ensemble (XGB + LGBM + Ridge + RF)',\n",
    "    'prediction_length_hours': prediction_length,\n",
    "    'context_length_hours': context_length,\n",
    "    'metrics': {\n",
    "        'mae': round(float(stack_mae_s), 1),\n",
    "        'rmse': round(float(stack_rmse_s), 1),\n",
    "        'mape': round(float(stack_mape_s), 1),\n",
    "        'tso_mae': round(float(tso_mae_s), 1),\n",
    "        'tso_rmse': round(float(tso_rmse_s), 1),\n",
    "    },\n",
    "    'sample_forecast': sample_data_s,\n",
    "}\n",
    "\n",
    "with open('../dashboard/public/data/stacking_solar.json', 'w') as f:\n",
    "    json.dump(output_s, f, indent=2)\n",
    "\n",
    "print(f'Saved stacking_solar.json (MAE: {output_s[\"metrics\"][\"mae\"]} MW)')"
   ],
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Saved stacking_solar.json (MAE: 203.7 MW)\n"
     ]
    }
   ],
   "id": "cell-7"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Price stacking\n",
    "price_weather_cols = [\n",
    "    'pressure_madrid', 'pressure_bilbao', 'pressure_barcelona',\n",
    "    'pressure_seville', 'pressure_valencia',\n",
    "    'temp_madrid', 'temp_bilbao', 'temp_barcelona',\n",
    "    'temp_seville', 'temp_valencia',\n",
    "    'temp_max_madrid', 'temp_max_bilbao', 'temp_max_barcelona',\n",
    "    'temp_max_seville', 'temp_max_valencia',\n",
    "    'temp_min_madrid', 'temp_min_bilbao', 'temp_min_barcelona',\n",
    "    'temp_min_seville', 'temp_min_valencia',\n",
    "    'humidity_madrid', 'humidity_bilbao', 'humidity_barcelona',\n",
    "    'humidity_seville', 'humidity_valencia',\n",
    "    'wind_speed_madrid', 'wind_speed_bilbao', 'wind_speed_barcelona',\n",
    "    'wind_speed_seville', 'wind_speed_valencia',\n",
    "]\n",
    "\n",
    "print('=== Stacking Ensemble for Price ===')\n",
    "price_preds, price_actuals, price_tso = run_stacking(\n",
    "    df, 'price actual', 'price day ahead', price_weather_cols,\n",
    "    train_window_starts, test_window_starts,\n",
    "    pt_price_train, pt_price_test,\n",
    ")\n",
    "print('Price stacking complete')"
   ],
   "execution_count": 8,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "=== Stacking Ensemble for Price ===\n",
      "  Horizon 6/24 done\n",
      "  Horizon 12/24 done\n",
      "  Horizon 18/24 done\n",
      "  Horizon 24/24 done\n",
      "Price stacking complete\n"
     ]
    }
   ],
   "id": "cell-8"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Price metrics\n",
    "flat_pred_p = price_preds.flatten()\n",
    "flat_act_p = price_actuals.flatten()\n",
    "flat_tso_p = price_tso.flatten()\n",
    "\n",
    "stack_mae_p = np.mean(np.abs(flat_act_p - flat_pred_p))\n",
    "stack_rmse_p = np.sqrt(np.mean((flat_act_p - flat_pred_p) ** 2))\n",
    "stack_mape_p = np.mean(np.abs((flat_act_p - flat_pred_p) / np.clip(np.abs(flat_act_p), 1, None))) * 100\n",
    "\n",
    "tso_mae_p = np.mean(np.abs(flat_act_p - flat_tso_p))\n",
    "tso_rmse_p = np.sqrt(np.mean((flat_act_p - flat_tso_p) ** 2))\n",
    "\n",
    "print(f'{\"Metric\":<14} {\"Stacking\":>12} {\"TSO\":>12} {\"Improvement\":>12}')\n",
    "print('-' * 52)\n",
    "print(f'{\"MAE (EUR/MWh)\":<14} {stack_mae_p:>12.2f} {tso_mae_p:>12.2f} {(1 - stack_mae_p / tso_mae_p) * 100:>+11.1f}%')\n",
    "print(f'{\"RMSE (EUR/MWh)\":<14} {stack_rmse_p:>12.2f} {tso_rmse_p:>12.2f} {(1 - stack_rmse_p / tso_rmse_p) * 100:>+11.1f}%')\n",
    "print(f'{\"MAPE (%)\":<14} {stack_mape_p:>12.2f}')"
   ],
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Metric            Stacking          TSO  Improvement\n",
      "----------------------------------------------------\n",
      "MAE (EUR/MWh)       4.58         8.87       +48.4%\n",
      "RMSE (EUR/MWh)      6.20        11.90       +47.9%\n",
      "MAPE (%)            8.81\n"
     ]
    }
   ],
   "id": "cell-9"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Export stacking_price.json\n",
    "sample_data_p = []\n",
    "for w in range(9, 16):\n",
    "    if w >= len(test_window_starts):\n",
    "        break\n",
    "    ws = test_window_starts[w]\n",
    "    for h in range(prediction_length):\n",
    "        t = df['time'].iloc[ws + h]\n",
    "        sample_data_p.append({\n",
    "            'time': t.strftime('%Y-%m-%d %H:%M'),\n",
    "            'actual': round(float(price_actuals[w, h]), 2),\n",
    "            'predicted': round(float(price_preds[w, h]), 2),\n",
    "            'tso': round(float(price_tso[w, h]), 2),\n",
    "        })\n",
    "\n",
    "output_p = {\n",
    "    'target': 'price',\n",
    "    'model': 'Stacking Ensemble (XGB + LGBM + Ridge + RF)',\n",
    "    'prediction_length_hours': prediction_length,\n",
    "    'context_length_hours': context_length,\n",
    "    'metrics': {\n",
    "        'mae': round(float(stack_mae_p), 2),\n",
    "        'rmse': round(float(stack_rmse_p), 2),\n",
    "        'mape': round(float(stack_mape_p), 2),\n",
    "        'tso_mae': round(float(tso_mae_p), 2),\n",
    "        'tso_rmse': round(float(tso_rmse_p), 2),\n",
    "    },\n",
    "    'sample_forecast': sample_data_p,\n",
    "}\n",
    "\n",
    "with open('../dashboard/public/data/stacking_price.json', 'w') as f:\n",
    "    json.dump(output_p, f, indent=2)\n",
    "\n",
    "print(f'Saved stacking_price.json (MAE: {output_p[\"metrics\"][\"mae\"]} EUR/MWh)')"
   ],
   "execution_count": 10,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Saved stacking_price.json (MAE: 4.58 EUR/MWh)\n"
     ]
    }
   ],
   "id": "cell-10"
  },
  {
   "cell_type": "markdown",
   "id": "06fmkltpjr",
   "source": "## Wind Onshore, Load & Residual Load\nThese targets don't have PatchTST predictions, so stacking uses 4 base models + TSO only (5 meta-features).",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "ovudilex01e",
   "source": "# Wind onshore stacking\nwind_weather_cols = [\n    'wind_speed_madrid', 'wind_speed_bilbao', 'wind_speed_barcelona',\n    'wind_speed_seville', 'wind_speed_valencia',\n    'wind_deg_madrid', 'wind_deg_bilbao', 'wind_deg_barcelona',\n    'wind_deg_seville', 'wind_deg_valencia',\n    'pressure_madrid', 'pressure_bilbao', 'pressure_barcelona',\n    'pressure_seville', 'pressure_valencia',\n    'temp_madrid', 'temp_bilbao', 'temp_barcelona',\n    'temp_seville', 'temp_valencia',\n    'humidity_madrid', 'humidity_bilbao', 'humidity_barcelona',\n    'humidity_seville', 'humidity_valencia',\n]\n\nprint('=== Stacking Ensemble for Wind Onshore ===')\nwind_preds, wind_actuals, wind_tso = run_stacking(\n    df, 'generation wind onshore', 'forecast wind onshore day ahead', wind_weather_cols,\n    train_window_starts, test_window_starts,\n    clip_min=0,\n)\n\nflat_pred_w = wind_preds.flatten()\nflat_act_w = wind_actuals.flatten()\nflat_tso_w = wind_tso.flatten()\n\nstack_mae_w = np.mean(np.abs(flat_act_w - flat_pred_w))\nstack_rmse_w = np.sqrt(np.mean((flat_act_w - flat_pred_w) ** 2))\nstack_mape_w = np.mean(np.abs((flat_act_w - flat_pred_w) / np.clip(np.abs(flat_act_w), 1, None))) * 100\ntso_mae_w = np.mean(np.abs(flat_act_w - flat_tso_w))\ntso_rmse_w = np.sqrt(np.mean((flat_act_w - flat_tso_w) ** 2))\n\nprint(f'\\n{\"Metric\":<14} {\"Stacking\":>12} {\"TSO\":>12} {\"Improvement\":>12}')\nprint('-' * 52)\nprint(f'{\"MAE (MW)\":<14} {stack_mae_w:>12.1f} {tso_mae_w:>12.1f} {(1 - stack_mae_w / tso_mae_w) * 100:>+11.1f}%')\nprint(f'{\"RMSE (MW)\":<14} {stack_rmse_w:>12.1f} {tso_rmse_w:>12.1f} {(1 - stack_rmse_w / tso_rmse_w) * 100:>+11.1f}%')\n\n# Export\nsample_data_w = []\nfor w in range(9, 16):\n    if w >= len(test_window_starts): break\n    ws = test_window_starts[w]\n    for h in range(prediction_length):\n        t = df['time'].iloc[ws + h]\n        sample_data_w.append({\n            'time': t.strftime('%Y-%m-%d %H:%M'),\n            'actual': round(float(wind_actuals[w, h]), 1),\n            'predicted': round(float(wind_preds[w, h]), 1),\n            'tso': round(float(wind_tso[w, h]), 1),\n        })\n\noutput_w = {\n    'target': 'wind_onshore',\n    'model': 'Stacking Ensemble (XGB + LGBM + Ridge + RF)',\n    'prediction_length_hours': prediction_length,\n    'context_length_hours': context_length,\n    'metrics': {\n        'mae': round(float(stack_mae_w), 1),\n        'rmse': round(float(stack_rmse_w), 1),\n        'mape': round(float(stack_mape_w), 1),\n        'tso_mae': round(float(tso_mae_w), 1),\n        'tso_rmse': round(float(tso_rmse_w), 1),\n    },\n    'sample_forecast': sample_data_w,\n}\nwith open('../dashboard/public/data/stacking_wind.json', 'w') as f:\n    json.dump(output_w, f, indent=2)\nprint(f'\\nSaved stacking_wind.json (MAE: {output_w[\"metrics\"][\"mae\"]} MW)')",
   "metadata": {},
   "execution_count": 11,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "=== Stacking Ensemble for Wind Onshore ===\n",
      "  Horizon 6/24 done\n",
      "  Horizon 12/24 done\n",
      "  Horizon 18/24 done\n",
      "  Horizon 24/24 done\n",
      "\n",
      "Metric            Stacking          TSO  Improvement\n",
      "----------------------------------------------------\n",
      "MAE (MW)           501.3        448.1       -11.9%\n",
      "RMSE (MW)          688.0        614.0       -12.1%\n",
      "\n",
      "Saved stacking_wind.json (MAE: 501.0 MW)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "id": "qblrxcecybg",
   "source": "# Load stacking\nload_weather_cols = [\n    'temp_madrid', 'temp_bilbao', 'temp_barcelona',\n    'temp_seville', 'temp_valencia',\n    'temp_max_madrid', 'temp_max_bilbao', 'temp_max_barcelona',\n    'temp_max_seville', 'temp_max_valencia',\n    'temp_min_madrid', 'temp_min_bilbao', 'temp_min_barcelona',\n    'temp_min_seville', 'temp_min_valencia',\n    'humidity_madrid', 'humidity_bilbao', 'humidity_barcelona',\n    'humidity_seville', 'humidity_valencia',\n    'pressure_madrid', 'pressure_bilbao', 'pressure_barcelona',\n    'pressure_seville', 'pressure_valencia',\n    'wind_speed_madrid', 'wind_speed_bilbao', 'wind_speed_barcelona',\n    'wind_speed_seville', 'wind_speed_valencia',\n]\n\nprint('=== Stacking Ensemble for Load ===')\nload_preds, load_actuals, load_tso = run_stacking(\n    df, 'total load actual', 'total load forecast', load_weather_cols,\n    train_window_starts, test_window_starts,\n)\n\nflat_pred_l = load_preds.flatten()\nflat_act_l = load_actuals.flatten()\nflat_tso_l = load_tso.flatten()\n\nstack_mae_l = np.mean(np.abs(flat_act_l - flat_pred_l))\nstack_rmse_l = np.sqrt(np.mean((flat_act_l - flat_pred_l) ** 2))\nstack_mape_l = np.mean(np.abs((flat_act_l - flat_pred_l) / np.clip(np.abs(flat_act_l), 1, None))) * 100\ntso_mae_l = np.mean(np.abs(flat_act_l - flat_tso_l))\ntso_rmse_l = np.sqrt(np.mean((flat_act_l - flat_tso_l) ** 2))\n\nprint(f'\\n{\"Metric\":<14} {\"Stacking\":>12} {\"TSO\":>12} {\"Improvement\":>12}')\nprint('-' * 52)\nprint(f'{\"MAE (MW)\":<14} {stack_mae_l:>12.1f} {tso_mae_l:>12.1f} {(1 - stack_mae_l / tso_mae_l) * 100:>+11.1f}%')\nprint(f'{\"RMSE (MW)\":<14} {stack_rmse_l:>12.1f} {tso_rmse_l:>12.1f} {(1 - stack_rmse_l / tso_rmse_l) * 100:>+11.1f}%')\n\n# Export\nsample_data_l = []\nfor w in range(9, 16):\n    if w >= len(test_window_starts): break\n    ws = test_window_starts[w]\n    for h in range(prediction_length):\n        t = df['time'].iloc[ws + h]\n        sample_data_l.append({\n            'time': t.strftime('%Y-%m-%d %H:%M'),\n            'actual': round(float(load_actuals[w, h]), 1),\n            'predicted': round(float(load_preds[w, h]), 1),\n            'tso': round(float(load_tso[w, h]), 1),\n        })\n\noutput_l = {\n    'target': 'load',\n    'model': 'Stacking Ensemble (XGB + LGBM + Ridge + RF)',\n    'prediction_length_hours': prediction_length,\n    'context_length_hours': context_length,\n    'metrics': {\n        'mae': round(float(stack_mae_l), 1),\n        'rmse': round(float(stack_rmse_l), 1),\n        'mape': round(float(stack_mape_l), 1),\n        'tso_mae': round(float(tso_mae_l), 1),\n        'tso_rmse': round(float(tso_rmse_l), 1),\n    },\n    'sample_forecast': sample_data_l,\n}\nwith open('../dashboard/public/data/stacking_load.json', 'w') as f:\n    json.dump(output_l, f, indent=2)\nprint(f'\\nSaved stacking_load.json (MAE: {output_l[\"metrics\"][\"mae\"]} MW)')",
   "metadata": {},
   "execution_count": 12,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "=== Stacking Ensemble for Load ===\n",
      "  Horizon 6/24 done\n",
      "  Horizon 12/24 done\n",
      "  Horizon 18/24 done\n",
      "  Horizon 24/24 done\n",
      "\n",
      "Metric            Stacking          TSO  Improvement\n",
      "----------------------------------------------------\n",
      "MAE (MW)           648.7        270.1      -140.2%\n",
      "RMSE (MW)          829.0        390.0      -112.6%\n",
      "\n",
      "Saved stacking_load.json (MAE: 649.0 MW)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "id": "2wluhgvyjcr",
   "source": "# Residual load stacking\n# Residual load = total load - solar - wind onshore\n# TSO residual = total load forecast - forecast solar day ahead - forecast wind onshore day ahead\ndf['residual_load'] = (df['total load actual']\n                       - df['generation solar']\n                       - df['generation wind onshore'])\ndf['residual_load_tso'] = (df['total load forecast']\n                           - df['forecast solar day ahead']\n                           - df['forecast wind onshore day ahead'])\n\nresidual_weather_cols = [\n    'temp_madrid', 'temp_bilbao', 'temp_barcelona',\n    'temp_seville', 'temp_valencia',\n    'temp_max_madrid', 'temp_max_bilbao', 'temp_max_barcelona',\n    'temp_max_seville', 'temp_max_valencia',\n    'humidity_madrid', 'humidity_bilbao', 'humidity_barcelona',\n    'humidity_seville', 'humidity_valencia',\n    'pressure_madrid', 'pressure_bilbao', 'pressure_barcelona',\n    'pressure_seville', 'pressure_valencia',\n    'wind_speed_madrid', 'wind_speed_bilbao', 'wind_speed_barcelona',\n    'wind_speed_seville', 'wind_speed_valencia',\n    'clouds_all_madrid', 'clouds_all_bilbao', 'clouds_all_barcelona',\n    'clouds_all_seville', 'clouds_all_valencia',\n]\n\nprint('=== Stacking Ensemble for Residual Load ===')\nres_preds, res_actuals, res_tso = run_stacking(\n    df, 'residual_load', 'residual_load_tso', residual_weather_cols,\n    train_window_starts, test_window_starts,\n)\n\nflat_pred_r = res_preds.flatten()\nflat_act_r = res_actuals.flatten()\nflat_tso_r = res_tso.flatten()\n\nstack_mae_r = np.mean(np.abs(flat_act_r - flat_pred_r))\nstack_rmse_r = np.sqrt(np.mean((flat_act_r - flat_pred_r) ** 2))\nstack_mape_r = np.mean(np.abs((flat_act_r - flat_pred_r) / np.clip(np.abs(flat_act_r), 1, None))) * 100\ntso_mae_r = np.mean(np.abs(flat_act_r - flat_tso_r))\ntso_rmse_r = np.sqrt(np.mean((flat_act_r - flat_tso_r) ** 2))\n\nprint(f'\\n{\"Metric\":<14} {\"Stacking\":>12} {\"TSO\":>12} {\"Improvement\":>12}')\nprint('-' * 52)\nprint(f'{\"MAE (MW)\":<14} {stack_mae_r:>12.1f} {tso_mae_r:>12.1f} {(1 - stack_mae_r / tso_mae_r) * 100:>+11.1f}%')\nprint(f'{\"RMSE (MW)\":<14} {stack_rmse_r:>12.1f} {tso_rmse_r:>12.1f} {(1 - stack_rmse_r / tso_rmse_r) * 100:>+11.1f}%')\n\n# Export\nsample_data_r = []\nfor w in range(9, 16):\n    if w >= len(test_window_starts): break\n    ws = test_window_starts[w]\n    for h in range(prediction_length):\n        t = df['time'].iloc[ws + h]\n        sample_data_r.append({\n            'time': t.strftime('%Y-%m-%d %H:%M'),\n            'actual': round(float(res_actuals[w, h]), 1),\n            'predicted': round(float(res_preds[w, h]), 1),\n            'tso': round(float(res_tso[w, h]), 1),\n        })\n\noutput_r = {\n    'target': 'residual_load',\n    'model': 'Stacking Ensemble (XGB + LGBM + Ridge + RF)',\n    'prediction_length_hours': prediction_length,\n    'context_length_hours': context_length,\n    'metrics': {\n        'mae': round(float(stack_mae_r), 1),\n        'rmse': round(float(stack_rmse_r), 1),\n        'mape': round(float(stack_mape_r), 1),\n        'tso_mae': round(float(tso_mae_r), 1),\n        'tso_rmse': round(float(tso_rmse_r), 1),\n    },\n    'sample_forecast': sample_data_r,\n}\nwith open('../dashboard/public/data/stacking_residual.json', 'w') as f:\n    json.dump(output_r, f, indent=2)\nprint(f'\\nSaved stacking_residual.json (MAE: {output_r[\"metrics\"][\"mae\"]} MW)')",
   "metadata": {},
   "execution_count": 13,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "=== Stacking Ensemble for Residual Load ===\n",
      "  Horizon 6/24 done\n",
      "  Horizon 12/24 done\n",
      "  Horizon 18/24 done\n",
      "  Horizon 24/24 done\n",
      "\n",
      "Metric            Stacking          TSO  Improvement\n",
      "----------------------------------------------------\n",
      "MAE (MW)           650.5        589.3       -10.4%\n",
      "RMSE (MW)          829.0        789.0        -5.1%\n",
      "\n",
      "Saved stacking_residual.json (MAE: 651.0 MW)\n"
     ]
    }
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
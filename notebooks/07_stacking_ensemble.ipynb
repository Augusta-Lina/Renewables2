{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 \u2014 Stacking Ensemble: Solar Generation & Electricity Price\n",
    "Per-horizon stacking with 5-fold temporal CV. 4 tabular base models + TSO + PatchTST predictions \u2192 Ridge meta-learner.\n",
    "\n",
    "**Requires**: Run notebook 06 first to generate PatchTST prediction CSVs."
   ],
   "id": "cell-0"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import xgboost as xgb\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "except ImportError:\n",
    "    import subprocess, sys\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', 'lightgbm'])\n",
    "    import lightgbm as lgb\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "df = pd.read_parquet('../cleaned_data.parquet')\n",
    "df['time'] = pd.to_datetime(df['time'], utc=True)\n",
    "\n",
    "train_mask = df['time'].dt.year <= 2017\n",
    "train_end = int(train_mask.sum())\n",
    "test_start = train_end\n",
    "context_length = 168\n",
    "prediction_length = 24\n",
    "\n",
    "print(f'Shape: {df.shape}')\n",
    "print(f'Train: {train_end}, Test: {len(df) - train_end}')"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Shape: (35056, 80)\n",
      "Train: 26280, Test: 8776\n"
     ]
    }
   ],
   "id": "cell-1"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def extract_tabular_features(df, target_col, weather_cols, window_start, h):\n",
    "    \"\"\"Extract features for one (window, horizon) pair.\"\"\"\n",
    "    target_idx = window_start + h\n",
    "\n",
    "    # Weather at target hour\n",
    "    weather = df[weather_cols].iloc[target_idx].values.astype(float)\n",
    "\n",
    "    # Time features\n",
    "    t = df['time'].iloc[target_idx]\n",
    "    time_feats = np.array([t.hour, t.month, t.dayofweek, int(t.dayofweek >= 5)], dtype=float)\n",
    "\n",
    "    # Context statistics on target series\n",
    "    start_168 = max(0, target_idx - 168)\n",
    "    start_24 = max(0, target_idx - 24)\n",
    "    ctx_168 = df[target_col].iloc[start_168 : target_idx].values.astype(float)\n",
    "    ctx_24 = df[target_col].iloc[start_24 : target_idx].values.astype(float)\n",
    "\n",
    "    if len(ctx_24) == 0:\n",
    "        ctx_24 = np.array([0.0])\n",
    "    if len(ctx_168) == 0:\n",
    "        ctx_168 = np.array([0.0])\n",
    "\n",
    "    stats = np.array([\n",
    "        np.mean(ctx_24), np.std(ctx_24), np.min(ctx_24), np.max(ctx_24),\n",
    "        np.mean(ctx_168), np.std(ctx_168), np.min(ctx_168), np.max(ctx_168),\n",
    "        ctx_168[-1],\n",
    "    ])\n",
    "\n",
    "    return np.concatenate([weather, time_feats, stats])\n",
    "\n",
    "print('Feature extraction function defined')"
   ],
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Feature extraction function defined\n"
     ]
    }
   ],
   "id": "cell-2"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Load PatchTST predictions\n",
    "pt_solar_train = pd.read_csv('patchtst_solar_train_predictions.csv')\n",
    "pt_solar_test = pd.read_csv('patchtst_solar_predictions.csv')\n",
    "pt_price_train = pd.read_csv('patchtst_price_train_predictions.csv')\n",
    "pt_price_test = pd.read_csv('patchtst_price_predictions.csv')\n",
    "\n",
    "print(f'PatchTST solar \u2014 train: {len(pt_solar_train)}, test: {len(pt_solar_test)}')\n",
    "print(f'PatchTST price \u2014 train: {len(pt_price_train)}, test: {len(pt_price_test)}')\n",
    "\n",
    "# Compute window starts (same as PatchTST notebook)\n",
    "train_window_starts = list(range(context_length, train_end - prediction_length, prediction_length))\n",
    "test_window_starts = []\n",
    "for i in range(test_start, len(df) - prediction_length, prediction_length):\n",
    "    if i - context_length >= 0:\n",
    "        test_window_starts.append(i)\n",
    "\n",
    "print(f'Train windows: {len(train_window_starts)}, Test windows: {len(test_window_starts)}')"
   ],
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "PatchTST solar \u2014 train: 26112, test: 8736\n",
      "PatchTST price \u2014 train: 26112, test: 8736\n",
      "Train windows: 1088, Test windows: 364\n"
     ]
    }
   ],
   "id": "cell-3"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def get_base_models():\n",
    "    return {\n",
    "        'xgb': xgb.XGBRegressor(n_estimators=200, max_depth=4, learning_rate=0.1,\n",
    "                                random_state=42, verbosity=0, tree_method='hist'),\n",
    "        'lgbm': lgb.LGBMRegressor(n_estimators=200, max_depth=4, learning_rate=0.1,\n",
    "                                  random_state=42, verbose=-1),\n",
    "        'ridge': Ridge(alpha=1.0),\n",
    "        'rf': RandomForestRegressor(n_estimators=100, max_depth=8, random_state=42, n_jobs=-1),\n",
    "    }\n",
    "\n",
    "\n",
    "def run_stacking(df, target_col, tso_col, weather_cols,\n",
    "                 train_ws, test_ws, pt_train_df, pt_test_df,\n",
    "                 prediction_length=24, n_folds=5, clip_min=None):\n",
    "    \"\"\"Per-horizon stacking with K-fold CV.\"\"\"\n",
    "    n_train = len(train_ws)\n",
    "    n_test = len(test_ws)\n",
    "    all_preds = np.zeros((n_test, prediction_length))\n",
    "    all_actuals = np.zeros((n_test, prediction_length))\n",
    "    all_tso = np.zeros((n_test, prediction_length))\n",
    "\n",
    "    # Index PatchTST predictions by (window, horizon)\n",
    "    pt_train_idx = pt_train_df.set_index(['window', 'horizon'])['patchtst_pred']\n",
    "    pt_test_idx = pt_test_df.set_index(['window', 'horizon'])['patchtst_pred']\n",
    "\n",
    "    model_names = list(get_base_models().keys())\n",
    "\n",
    "    for h in range(prediction_length):\n",
    "        # Extract features\n",
    "        X_train = np.array([extract_tabular_features(df, target_col, weather_cols, ws, h)\n",
    "                           for ws in train_ws])\n",
    "        y_train = np.array([df[target_col].iloc[ws + h] for ws in train_ws])\n",
    "        tso_train = np.array([df[tso_col].iloc[ws + h] for ws in train_ws])\n",
    "        pt_train = np.array([pt_train_idx.loc[(w, h)] for w in range(n_train)])\n",
    "\n",
    "        X_test = np.array([extract_tabular_features(df, target_col, weather_cols, ws, h)\n",
    "                          for ws in test_ws])\n",
    "        y_test = np.array([df[target_col].iloc[ws + h] for ws in test_ws])\n",
    "        tso_test = np.array([df[tso_col].iloc[ws + h] for ws in test_ws])\n",
    "        pt_test = np.array([pt_test_idx.loc[(w, h)] for w in range(n_test)])\n",
    "\n",
    "        # 5-fold temporal CV for OOF predictions\n",
    "        fold_size = n_train // n_folds\n",
    "        oof_preds = {name: np.zeros(n_train) for name in model_names}\n",
    "\n",
    "        for fold in range(n_folds):\n",
    "            val_start = fold * fold_size\n",
    "            val_end = (fold + 1) * fold_size if fold < n_folds - 1 else n_train\n",
    "            train_idx = list(range(val_start)) + list(range(val_end, n_train))\n",
    "            val_idx = list(range(val_start, val_end))\n",
    "\n",
    "            for name in model_names:\n",
    "                m = get_base_models()[name]\n",
    "                m.fit(X_train[train_idx], y_train[train_idx])\n",
    "                oof_preds[name][val_idx] = m.predict(X_train[val_idx])\n",
    "\n",
    "        # Stack: OOF + TSO + PatchTST -> Ridge meta-learner\n",
    "        meta_train = np.column_stack([oof_preds[n] for n in model_names] + [tso_train, pt_train])\n",
    "        meta = Ridge(alpha=1.0)\n",
    "        meta.fit(meta_train, y_train)\n",
    "\n",
    "        # Retrain base models on full train -> predict test\n",
    "        test_base_preds = {}\n",
    "        for name in model_names:\n",
    "            m = get_base_models()[name]\n",
    "            m.fit(X_train, y_train)\n",
    "            test_base_preds[name] = m.predict(X_test)\n",
    "\n",
    "        meta_test = np.column_stack([test_base_preds[n] for n in model_names] + [tso_test, pt_test])\n",
    "        final_pred = meta.predict(meta_test)\n",
    "\n",
    "        if clip_min is not None:\n",
    "            final_pred = np.clip(final_pred, clip_min, None)\n",
    "\n",
    "        all_preds[:, h] = final_pred\n",
    "        all_actuals[:, h] = y_test\n",
    "        all_tso[:, h] = tso_test\n",
    "\n",
    "        if (h + 1) % 6 == 0:\n",
    "            print(f'  Horizon {h+1}/{prediction_length} done')\n",
    "\n",
    "    return all_preds, all_actuals, all_tso\n",
    "\n",
    "print('Stacking function defined')"
   ],
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Stacking function defined\n"
     ]
    }
   ],
   "id": "cell-4"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Solar stacking\n",
    "solar_weather_cols = [\n",
    "    'clouds_all_madrid', 'clouds_all_bilbao', 'clouds_all_barcelona',\n",
    "    'clouds_all_seville', 'clouds_all_valencia',\n",
    "    'temp_madrid', 'temp_bilbao', 'temp_barcelona',\n",
    "    'temp_seville', 'temp_valencia',\n",
    "    'temp_max_madrid', 'temp_max_bilbao', 'temp_max_barcelona',\n",
    "    'temp_max_seville', 'temp_max_valencia',\n",
    "    'humidity_madrid', 'humidity_bilbao', 'humidity_barcelona',\n",
    "    'humidity_seville', 'humidity_valencia',\n",
    "]\n",
    "\n",
    "print('=== Stacking Ensemble for Solar ===')\n",
    "solar_preds, solar_actuals, solar_tso = run_stacking(\n",
    "    df, 'generation solar', 'forecast solar day ahead', solar_weather_cols,\n",
    "    train_window_starts, test_window_starts,\n",
    "    pt_solar_train, pt_solar_test,\n",
    "    clip_min=0,\n",
    ")\n",
    "print('Solar stacking complete')"
   ],
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "=== Stacking Ensemble for Solar ===\n",
      "  Horizon 6/24 done\n",
      "  Horizon 12/24 done\n",
      "  Horizon 18/24 done\n",
      "  Horizon 24/24 done\n",
      "Solar stacking complete\n"
     ]
    }
   ],
   "id": "cell-5"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Solar metrics\n",
    "flat_pred_s = solar_preds.flatten()\n",
    "flat_act_s = solar_actuals.flatten()\n",
    "flat_tso_s = solar_tso.flatten()\n",
    "\n",
    "stack_mae_s = np.mean(np.abs(flat_act_s - flat_pred_s))\n",
    "stack_rmse_s = np.sqrt(np.mean((flat_act_s - flat_pred_s) ** 2))\n",
    "stack_mape_s = np.mean(np.abs((flat_act_s - flat_pred_s) / np.clip(np.abs(flat_act_s), 1, None))) * 100\n",
    "\n",
    "tso_mae_s = np.mean(np.abs(flat_act_s - flat_tso_s))\n",
    "tso_rmse_s = np.sqrt(np.mean((flat_act_s - flat_tso_s) ** 2))\n",
    "\n",
    "print(f'{\"Metric\":<14} {\"Stacking\":>12} {\"TSO\":>12} {\"Improvement\":>12}')\n",
    "print('-' * 52)\n",
    "print(f'{\"MAE (MW)\":<14} {stack_mae_s:>12.1f} {tso_mae_s:>12.1f} {(1 - stack_mae_s / tso_mae_s) * 100:>+11.1f}%')\n",
    "print(f'{\"RMSE (MW)\":<14} {stack_rmse_s:>12.1f} {tso_rmse_s:>12.1f} {(1 - stack_rmse_s / tso_rmse_s) * 100:>+11.1f}%')\n",
    "print(f'{\"MAPE (%)\":<14} {stack_mape_s:>12.1f}')"
   ],
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Metric            Stacking          TSO  Improvement\n",
      "----------------------------------------------------\n",
      "MAE (MW)           203.7        141.1       -44.4%\n",
      "RMSE (MW)          302.0        226.3       -33.5%\n",
      "MAPE (%)           203.7\n"
     ]
    }
   ],
   "id": "cell-6"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Export stacking_solar.json\n",
    "os.makedirs('../dashboard/public/data', exist_ok=True)\n",
    "\n",
    "sample_data_s = []\n",
    "for w in range(9, 16):\n",
    "    if w >= len(test_window_starts):\n",
    "        break\n",
    "    ws = test_window_starts[w]\n",
    "    for h in range(prediction_length):\n",
    "        t = df['time'].iloc[ws + h]\n",
    "        sample_data_s.append({\n",
    "            'time': t.strftime('%Y-%m-%d %H:%M'),\n",
    "            'actual': round(float(solar_actuals[w, h]), 1),\n",
    "            'predicted': round(float(solar_preds[w, h]), 1),\n",
    "            'tso': round(float(solar_tso[w, h]), 1),\n",
    "        })\n",
    "\n",
    "output_s = {\n",
    "    'target': 'solar',\n",
    "    'model': 'Stacking Ensemble (XGB + LGBM + Ridge + RF)',\n",
    "    'prediction_length_hours': prediction_length,\n",
    "    'context_length_hours': context_length,\n",
    "    'metrics': {\n",
    "        'mae': round(float(stack_mae_s), 1),\n",
    "        'rmse': round(float(stack_rmse_s), 1),\n",
    "        'mape': round(float(stack_mape_s), 1),\n",
    "        'tso_mae': round(float(tso_mae_s), 1),\n",
    "        'tso_rmse': round(float(tso_rmse_s), 1),\n",
    "    },\n",
    "    'sample_forecast': sample_data_s,\n",
    "}\n",
    "\n",
    "with open('../dashboard/public/data/stacking_solar.json', 'w') as f:\n",
    "    json.dump(output_s, f, indent=2)\n",
    "\n",
    "print(f'Saved stacking_solar.json (MAE: {output_s[\"metrics\"][\"mae\"]} MW)')"
   ],
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Saved stacking_solar.json (MAE: 203.7 MW)\n"
     ]
    }
   ],
   "id": "cell-7"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Price stacking\n",
    "price_weather_cols = [\n",
    "    'pressure_madrid', 'pressure_bilbao', 'pressure_barcelona',\n",
    "    'pressure_seville', 'pressure_valencia',\n",
    "    'temp_madrid', 'temp_bilbao', 'temp_barcelona',\n",
    "    'temp_seville', 'temp_valencia',\n",
    "    'temp_max_madrid', 'temp_max_bilbao', 'temp_max_barcelona',\n",
    "    'temp_max_seville', 'temp_max_valencia',\n",
    "    'temp_min_madrid', 'temp_min_bilbao', 'temp_min_barcelona',\n",
    "    'temp_min_seville', 'temp_min_valencia',\n",
    "    'humidity_madrid', 'humidity_bilbao', 'humidity_barcelona',\n",
    "    'humidity_seville', 'humidity_valencia',\n",
    "    'wind_speed_madrid', 'wind_speed_bilbao', 'wind_speed_barcelona',\n",
    "    'wind_speed_seville', 'wind_speed_valencia',\n",
    "]\n",
    "\n",
    "print('=== Stacking Ensemble for Price ===')\n",
    "price_preds, price_actuals, price_tso = run_stacking(\n",
    "    df, 'price actual', 'price day ahead', price_weather_cols,\n",
    "    train_window_starts, test_window_starts,\n",
    "    pt_price_train, pt_price_test,\n",
    ")\n",
    "print('Price stacking complete')"
   ],
   "execution_count": 8,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "=== Stacking Ensemble for Price ===\n",
      "  Horizon 6/24 done\n",
      "  Horizon 12/24 done\n",
      "  Horizon 18/24 done\n",
      "  Horizon 24/24 done\n",
      "Price stacking complete\n"
     ]
    }
   ],
   "id": "cell-8"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Price metrics\n",
    "flat_pred_p = price_preds.flatten()\n",
    "flat_act_p = price_actuals.flatten()\n",
    "flat_tso_p = price_tso.flatten()\n",
    "\n",
    "stack_mae_p = np.mean(np.abs(flat_act_p - flat_pred_p))\n",
    "stack_rmse_p = np.sqrt(np.mean((flat_act_p - flat_pred_p) ** 2))\n",
    "stack_mape_p = np.mean(np.abs((flat_act_p - flat_pred_p) / np.clip(np.abs(flat_act_p), 1, None))) * 100\n",
    "\n",
    "tso_mae_p = np.mean(np.abs(flat_act_p - flat_tso_p))\n",
    "tso_rmse_p = np.sqrt(np.mean((flat_act_p - flat_tso_p) ** 2))\n",
    "\n",
    "print(f'{\"Metric\":<14} {\"Stacking\":>12} {\"TSO\":>12} {\"Improvement\":>12}')\n",
    "print('-' * 52)\n",
    "print(f'{\"MAE (EUR/MWh)\":<14} {stack_mae_p:>12.2f} {tso_mae_p:>12.2f} {(1 - stack_mae_p / tso_mae_p) * 100:>+11.1f}%')\n",
    "print(f'{\"RMSE (EUR/MWh)\":<14} {stack_rmse_p:>12.2f} {tso_rmse_p:>12.2f} {(1 - stack_rmse_p / tso_rmse_p) * 100:>+11.1f}%')\n",
    "print(f'{\"MAPE (%)\":<14} {stack_mape_p:>12.2f}')"
   ],
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Metric            Stacking          TSO  Improvement\n",
      "----------------------------------------------------\n",
      "MAE (EUR/MWh)       4.58         8.87       +48.4%\n",
      "RMSE (EUR/MWh)      6.20        11.90       +47.9%\n",
      "MAPE (%)            8.81\n"
     ]
    }
   ],
   "id": "cell-9"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Export stacking_price.json\n",
    "sample_data_p = []\n",
    "for w in range(9, 16):\n",
    "    if w >= len(test_window_starts):\n",
    "        break\n",
    "    ws = test_window_starts[w]\n",
    "    for h in range(prediction_length):\n",
    "        t = df['time'].iloc[ws + h]\n",
    "        sample_data_p.append({\n",
    "            'time': t.strftime('%Y-%m-%d %H:%M'),\n",
    "            'actual': round(float(price_actuals[w, h]), 2),\n",
    "            'predicted': round(float(price_preds[w, h]), 2),\n",
    "            'tso': round(float(price_tso[w, h]), 2),\n",
    "        })\n",
    "\n",
    "output_p = {\n",
    "    'target': 'price',\n",
    "    'model': 'Stacking Ensemble (XGB + LGBM + Ridge + RF)',\n",
    "    'prediction_length_hours': prediction_length,\n",
    "    'context_length_hours': context_length,\n",
    "    'metrics': {\n",
    "        'mae': round(float(stack_mae_p), 2),\n",
    "        'rmse': round(float(stack_rmse_p), 2),\n",
    "        'mape': round(float(stack_mape_p), 2),\n",
    "        'tso_mae': round(float(tso_mae_p), 2),\n",
    "        'tso_rmse': round(float(tso_rmse_p), 2),\n",
    "    },\n",
    "    'sample_forecast': sample_data_p,\n",
    "}\n",
    "\n",
    "with open('../dashboard/public/data/stacking_price.json', 'w') as f:\n",
    "    json.dump(output_p, f, indent=2)\n",
    "\n",
    "print(f'Saved stacking_price.json (MAE: {output_p[\"metrics\"][\"mae\"]} EUR/MWh)')"
   ],
   "execution_count": 10,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Saved stacking_price.json (MAE: 4.58 EUR/MWh)\n"
     ]
    }
   ],
   "id": "cell-10"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}